<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>7 Colab prerequisites - RAG Cookbooks</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "7 Colab prerequisites";
        var mkdocs_page_input_path = "stage7_colab_prereqs.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> RAG Cookbooks
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../stage1_overview/">1 High‑level overview</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../stage2_deep_theory/">2  Deep Theory (First-Principles Explanation)</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../stage3_components/">3  Core components</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../stage4_pipeline/">4 Pipeline walkthrough</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../stage5_variants/">5 RAG Variants</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../stage6_limitations/">6 Limitations & debugging</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">7 Colab prerequisites</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#bluf">BLUF</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../stage8_summary/">8 Final summary & checklist</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">RAG Cookbooks</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">7 Colab prerequisites</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h2 id="stage-7-minimal-prerequisites-for-a-colab-prototype">Stage 7 – Minimal Prerequisites for a Colab Prototype</h2>
<h3 id="bluf">BLUF</h3>
<p>To build the <strong>smallest possible working RAG</strong> in Google Colab, you only need:</p>
<ol>
<li>a few files, 2) one embedding model, 3) one vector DB, 4) one retriever, 5) one LLM call.
   Nothing else.</li>
</ol>
<hr />
<h1 id="1-minimal-conceptual-requirements">1. Minimal Conceptual Requirements</h1>
<h3 id="a-one-small-corpus">A. One small corpus</h3>
<p>Examples:</p>
<ul>
<li>A text file</li>
<li>A PDF converted to text</li>
<li>A folder of <code>.txt</code> notes</li>
<li>A few paragraphs you paste manually</li>
</ul>
<p>Keep it tiny to reduce noise.</p>
<hr />
<h3 id="b-a-chunker">B. A chunker</h3>
<p>Simplest possible:</p>
<ul>
<li>Fixed size: 300–500 tokens</li>
<li>Overlap: 50–100 tokens</li>
<li>Use recursive text splitter in LangChain or a simple Python function</li>
</ul>
<hr />
<h3 id="c-an-embedding-model">C. An embedding model</h3>
<p>Pick one:</p>
<ul>
<li><strong>bge-small-en</strong> (fast, free, excellent)</li>
<li><strong>sentence-transformers/all-MiniLM-L6-v2</strong></li>
<li><strong>text-embedding-3-small</strong> (OpenAI; optional)</li>
</ul>
<p>For Colab: sentence-transformers is easiest.</p>
<hr />
<h3 id="d-a-vector-store">D. A vector store</h3>
<p>Simplest/local options:</p>
<ul>
<li><strong>FAISS</strong> (best for Colab)</li>
<li>Chroma (optional)</li>
</ul>
<p>FAISS keeps everything in RAM → zero infra complexity.</p>
<hr />
<h3 id="e-a-retriever">E. A retriever</h3>
<p>FAISSStore.asRetriever(k=3) or Chroma.asRetriever().</p>
<hr />
<h3 id="f-an-llm">F. An LLM</h3>
<p>At minimal:</p>
<ul>
<li><strong>GPT-4o-mini</strong> or <strong>GPT-4.1</strong> via API</li>
<li>Or a local model like <strong>Qwen2.5 0.5B</strong> via transformers (only for demonstration)</li>
</ul>
<p>For Colab, simplest working pipeline uses OpenAI API.</p>
<hr />
<h1 id="2-minimal-technical-requirements-software">2. Minimal Technical Requirements (Software)</h1>
<p>Install only these:</p>
<pre><code>pip install langchain sentence-transformers faiss-cpu openai
</code></pre>
<p>Optional:</p>
<ul>
<li>PyPDF2 for PDFs</li>
<li>tiktoken for token counting</li>
</ul>
<hr />
<h1 id="3-minimum-pipeline-executable-sequence">3. Minimum Pipeline (Executable Sequence)</h1>
<h3 id="step-1-load-documents">Step 1. Load documents</h3>
<ul>
<li>Read <code>.txt</code> or extract text from PDF</li>
</ul>
<h3 id="step-2-chunk-the-text">Step 2. Chunk the text</h3>
<ul>
<li>Use LangChain’s RecursiveCharacterTextSplitter or your own</li>
</ul>
<h3 id="step-3-embed-chunks">Step 3. Embed chunks</h3>
<ul>
<li>Using Sentence Transformers model</li>
<li>Produce vectors</li>
</ul>
<h3 id="step-4-build-index">Step 4. Build index</h3>
<ul>
<li>Store vectors in FAISS</li>
<li>Save chunk texts as metadata</li>
</ul>
<h3 id="step-5-build-retriever">Step 5. Build retriever</h3>
<ul>
<li>FAISS → retriever</li>
</ul>
<h3 id="step-6-build-rag-chain">Step 6. Build RAG chain</h3>
<ul>
<li>Query → embed → retrieve top-K chunks → format prompt → LLM → answer</li>
</ul>
<h3 id="step-7-test">Step 7. Test</h3>
<p>Ask a question and inspect:</p>
<ul>
<li>Retrieved chunks</li>
<li>Generated answer</li>
</ul>
<hr />
<h1 id="4-minimal-working-rag-code-skeleton-pseudocode">4. Minimal Working RAG Code Skeleton (Pseudocode)</h1>
<p><strong>This is not full code; it’s the conceptual “shape” of the notebook.</strong></p>
<pre><code># 1. Load text
text = open('notes.txt').read()

# 2. Chunk
chunks = chunk(text, size=500, overlap=100)

# 3. Embed
embeddings = embed(chunks)

# 4. Index
faiss_index = FAISS.from_embeddings(embeddings, chunks)

# 5. Retriever
retriever = faiss_index.as_retriever(k=5)

# 6. Query
query = &quot;What does the document say about X?&quot;
query_vector = embed(query)

results = retriever.get_relevant_documents(query)

# 7. Prompt + LLM
answer = call_llm(query, results)

print(answer)
</code></pre>
<p>This is literally all needed for the smallest RAG demo.</p>
<hr />
<h1 id="5-minimal-notebook-structure-810-cells">5. Minimal Notebook Structure (8–10 cells)</h1>
<ol>
<li>Install packages</li>
<li>Import libraries</li>
<li>Load data</li>
<li>Chunk data</li>
<li>Load embedding model</li>
<li>Generate + store embeddings</li>
<li>Build FAISS index</li>
<li>Query via retriever</li>
<li>Build prompt</li>
<li>Call LLM</li>
</ol>
<hr />
<h1 id="6-practical-tips-for-the-beginner-prototype">6. Practical Tips for the Beginner Prototype</h1>
<ul>
<li>Use <strong>very small datasets</strong> (2–3 paragraphs) so you can inspect every chunk.</li>
<li>Print <strong>retrieved chunks</strong> each time; this is essential for learning retrieval behavior.</li>
<li>Start with <strong>top_k = 3</strong>.</li>
<li>Keep your LLM prompt extremely simple in Stage 1.</li>
<li>Do not add rerankers, hybrid search, or agent pipelines initially.</li>
</ul>
<p>Goal: <strong>functional correctness, not sophistication</strong>.</p>
<hr />
<h1 id="7-smallest-buildable-rag-architecture-diagram">7. Smallest Buildable RAG Architecture Diagram</h1>
<pre><code>Documents ─→ Chunker ─→ Embedder ─→ FAISS Index
                                            │
                                    Query ─→│
                                            ▼
                                        Retriever
                                            │
                                            ▼
                                   Prompt Constructor
                                            │
                                            ▼
                                           LLM
                                            ▼
                                          Answer
</code></pre>
<hr />
<p>Stage 7 complete.
Say <strong>“continue”</strong> to proceed to <strong>Stage 8 → Final ultra-short summary + learning checklist</strong>.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../stage6_limitations/" class="btn btn-neutral float-left" title="6 Limitations & debugging"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../stage8_summary/" class="btn btn-neutral float-right" title="8 Final summary & checklist">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../stage6_limitations/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../stage8_summary/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
