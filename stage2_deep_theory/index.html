<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>2  Deep Theory (First-Principles Explanation) - RAG Cookbooks</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "2  Deep Theory (First-Principles Explanation)";
        var mkdocs_page_input_path = "stage2_deep_theory.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> RAG Cookbooks
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../stage1_overview/">1 High‑level overview</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">2  Deep Theory (First-Principles Explanation)</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#1-why-llms-need-external-retrieval">1. Why LLMs need external retrieval</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#2-formal-rag-idea-conceptual-math">2. Formal RAG idea (conceptual math)</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#3-embeddings-as-the-retrieval-backbone">3. Embeddings as the retrieval backbone</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#4-vector-database-theory-what-makes-it-special">4. Vector database theory (what makes it special)</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#5-retriever-theory">5. Retriever theory</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#6-generator-llm-theory-how-conditioning-works">6. Generator (LLM) theory: How conditioning works</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#7-theoretical-benefits-of-rag">7. Theoretical benefits of RAG</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#8-theoretical-failure-modes-root-causes">8. Theoretical failure modes (root causes)</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#9-where-theory-meets-practice">9. Where theory meets practice</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../stage3_components/">3  Core components</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../stage4_pipeline/">4 Pipeline walkthrough</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../stage5_variants/">5 RAG Variants</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../stage6_limitations/">6 Limitations & debugging</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../stage7_colab_prereqs/">7 Colab prerequisites</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../stage8_summary/">8 Final summary & checklist</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">RAG Cookbooks</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">2  Deep Theory (First-Principles Explanation)</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h2 id="stage-2-deep-theory-first-principles-explanation">Stage 2 – Deep Theory (First-Principles Explanation)</h2>
<h3 id="1-why-llms-need-external-retrieval">1. Why LLMs need external retrieval</h3>
<p>LLMs = probabilistic next-token predictors.</p>
<p>Fundamentals:</p>
<ul>
<li>They <strong>do not store facts explicitly</strong>; they store statistical patterns.</li>
<li>
<p>Their “knowledge” is:</p>
</li>
<li>
<p>approximate</p>
</li>
<li>compressed</li>
<li>static (frozen after training)</li>
<li>
<p>They cannot:</p>
</li>
<li>
<p>add new knowledge without retraining</p>
</li>
<li>guarantee factual recall</li>
<li>remember large custom corpora on demand</li>
</ul>
<p>Conclusion:
<strong>LLMs alone cannot guarantee correctness or freshness.</strong>
RAG adds a deterministic information source to fix this.</p>
<hr />
<h3 id="2-formal-rag-idea-conceptual-math">2. Formal RAG idea (conceptual math)</h3>
<p>Break the answer generation into two conditional steps:</p>
<ol>
<li>
<p><strong>Retrieval step:</strong>
   Select a set of documents (D^<em>) from a corpus (C) that are relevant to a query (q).
   Conceptually:
   (D^</em> = \text{Retrieve}(q, C))</p>
</li>
<li>
<p><strong>Generation step:</strong>
   Use an LLM to produce an answer conditioned on both the query and retrieved documents.
   Conceptually:
   (A = \text{LLM}(q, D^*))</p>
</li>
</ol>
<p>This separates:</p>
<ul>
<li><strong>Knowledge selection</strong>
  (deterministic, index-based)</li>
<li><strong>Natural language reasoning</strong>
  (probabilistic, model-based)</li>
</ul>
<p>This two-stage decomposition is core to RAG.</p>
<hr />
<h3 id="3-embeddings-as-the-retrieval-backbone">3. Embeddings as the retrieval backbone</h3>
<p>Intuition:</p>
<ul>
<li>Convert text into a vector (dense representation)</li>
<li>Semantic similarity ≈ geometric closeness</li>
<li>Allows “meaning-based” search instead of keyword search</li>
</ul>
<p>Properties:</p>
<ul>
<li>Embedding models produce vectors in 384–4096 dimensions</li>
<li>
<p>Similarity computed via:</p>
</li>
<li>
<p>cosine similarity</p>
</li>
<li>dot product</li>
<li>Euclidean distance (rare in RAG)</li>
</ul>
<p>Core theoretical idea:
<strong>Semantic meaning → geometry</strong>
Text with similar meaning → vectors close in space.</p>
<hr />
<h3 id="4-vector-database-theory-what-makes-it-special">4. Vector database theory (what makes it special)</h3>
<p>A vector DB needs to solve two problems:</p>
<ol>
<li><strong>Indexing</strong> large numbers of high-dimensional vectors</li>
<li><strong>Fast approximate nearest neighbor search (ANN)</strong>
   → retrieves top-k closest vectors in milliseconds</li>
</ol>
<p>ANN algorithms:</p>
<ul>
<li>HNSW (Hierarchical Navigable Small World)</li>
<li>IVF/Flat</li>
<li>Product quantization</li>
<li>Graph-based search</li>
</ul>
<p>Key theory:
Trade <strong>perfect accuracy</strong> for <strong>massive speed gains</strong> with negligible correctness loss.</p>
<hr />
<h3 id="5-retriever-theory">5. Retriever theory</h3>
<p>A retriever selects relevant chunks from the corpus. Two main approaches:</p>
<p><strong>A. Dense retrieval (default in modern RAG)</strong></p>
<ul>
<li>Compare query embedding with chunk embeddings</li>
<li>Strength: semantic match</li>
<li>Weakness: may miss keyword-specific info (e.g., numbers, rare entities)</li>
</ul>
<p><strong>B. Sparse retrieval (classic search)</strong></p>
<ul>
<li>BM25, TF-IDF</li>
<li>Strength: exact term matching, good for numbers, names</li>
<li>Weakness: poor semantic understanding</li>
</ul>
<p>RAG often uses <strong>hybrid retrieval</strong> = dense + sparse.</p>
<hr />
<h3 id="6-generator-llm-theory-how-conditioning-works">6. Generator (LLM) theory: How conditioning works</h3>
<p>LLMs condition on text via attention:</p>
<ul>
<li>Input tokens = question + retrieved chunks</li>
<li>Self-attention creates token–token relationships</li>
<li>The model grounds its answer on provided chunk tokens
  (if prompted correctly)</li>
</ul>
<p>Important theoretical limits:</p>
<ul>
<li><strong>Context window</strong> determines max number of tokens it can consider</li>
<li>More chunks ≠ always better (attention dilution)</li>
</ul>
<hr />
<h3 id="7-theoretical-benefits-of-rag">7. Theoretical benefits of RAG</h3>
<ul>
<li><strong>Compositionality:</strong> Separate “knowledge lookup” from “reasoning”</li>
<li><strong>Scalable:</strong> Add documents without retraining the LLM</li>
<li><strong>Controllable:</strong> Swap retriever, adjust chunking, tweak index</li>
<li><strong>Auditable:</strong> Show retrieved sources; explain why an answer was produced</li>
<li><strong>Freshness:</strong> Index can be updated daily/hourly</li>
</ul>
<hr />
<h3 id="8-theoretical-failure-modes-root-causes">8. Theoretical failure modes (root causes)</h3>
<ol>
<li>
<p><strong>Retrieval failure</strong>
   Wrong or irrelevant chunks retrieved
   → Generator hallucinates or guesses</p>
</li>
<li>
<p><strong>Context overload</strong>
   Too many chunks reduce attention fidelity</p>
</li>
<li>
<p><strong>Semantic gap</strong>
   Embedding model misrepresents niche topics</p>
</li>
<li>
<p><strong>Chunking mismatch</strong>
   Chunks too small → lost context
   Chunks too large → irrelevant noisy text</p>
</li>
<li>
<p><strong>LLM drift</strong>
   Model invents details unless forced to use the context</p>
</li>
</ol>
<p>RAG theory = “fix retrieval, fix chunking, fix prompt → fix system.”</p>
<hr />
<h3 id="9-where-theory-meets-practice">9. Where theory meets practice</h3>
<p>Real RAG = orchestration of:</p>
<ul>
<li>Representation (embeddings)</li>
<li>Indexing (vector DB)</li>
<li>Routing (retriever)</li>
<li>Context construction (prompt)</li>
<li>Generation (LLM)</li>
</ul>
<p>Each part has independent theoretical assumptions; breaking one breaks the chain.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../stage1_overview/" class="btn btn-neutral float-left" title="1 High‑level overview"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../stage3_components/" class="btn btn-neutral float-right" title="3  Core components">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../stage1_overview/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../stage3_components/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
